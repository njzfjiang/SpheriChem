{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e6f041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850b281",
   "metadata": {},
   "source": [
    "## Load the dataset and pre process\n",
    "Note: here we use simulated linear positions for GNN (positions are used only for distance-based connectivity), while real 3D molecular coordinates are available for GSCNN (which requires accurate geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5e5be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "  X (Coulomb matrices): (7211, 23, 23)\n",
      "  T (Properties): (7211, 14)\n",
      "Extracted Z for 7211 molecules\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat('../qm7b.mat')\n",
    "\n",
    "# Extract available data\n",
    "X = data['X']  # Coulomb matrices: (7211, 23, 23)\n",
    "T = data['T']  # Properties: (7211, 14)\n",
    "names = data['names']  # Property names: (14,)\n",
    "\n",
    "X = np.array(X)\n",
    "T = np.array(T)\n",
    "\n",
    "# Get property names\n",
    "if names.ndim > 1:\n",
    "    property_names = [str(names[i][0]) for i in range(len(names))]\n",
    "else:\n",
    "    property_names = [str(names[i]) for i in range(len(names))]\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"  X (Coulomb matrices): {X.shape}\")\n",
    "print(f\"  T (Properties): {T.shape}\")\n",
    "\n",
    "# Extract atomic numbers from Coulomb matrix diagonals\n",
    "# C_ii = 0.5 * Z_i^2.4, so Z_i = (2 * C_ii)^(1/2.4)\n",
    "Z_list = []\n",
    "for i in range(len(X)):\n",
    "    coulomb_diag = np.diag(X[i])\n",
    "    # Find non-zero diagonal elements (actual atoms)\n",
    "    atom_indices = np.where(coulomb_diag > 1e-6)[0]\n",
    "    if len(atom_indices) > 0:\n",
    "        z_vals = (2 * coulomb_diag[atom_indices]) ** (1.0 / 2.4)\n",
    "        z_vals = np.round(z_vals).astype(int)\n",
    "        Z_list.append(z_vals)\n",
    "    else:\n",
    "        Z_list.append(np.array([1]))\n",
    "\n",
    "\n",
    "R_list = []\n",
    "for i, z_vals in enumerate(Z_list):\n",
    "    n_atoms = len(z_vals)\n",
    "    r_vals = np.zeros((n_atoms, 3))\n",
    "    for j in range(n_atoms):\n",
    "        r_vals[j, 0] = j * 1.5  # Simple spacing along x-axis\n",
    "    R_list.append(r_vals)\n",
    "\n",
    "Z = np.array(Z_list, dtype=object)\n",
    "R = np.array(R_list, dtype=object)\n",
    "\n",
    "print(f\"Extracted Z for {len(Z)} molecules\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675bb8e",
   "metadata": {},
   "source": [
    "## GCN Architecture\n",
    "\n",
    "Define GCNConv, GCNLayer (with residual connections), and GCN model (embedding → GCN layers → atom-wise MLP → property prediction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27b28538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(nn.Module):\n",
    "    \"\"\"Graph Convolutional Network Convolution Layer\"\"\"\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "        \n",
    "    def forward(self, x, edge_index, mask):\n",
    "        \"\"\"\n",
    "        GCN convolution: normalized aggregation\n",
    "        For each node: aggregate normalized neighbor features + self features\n",
    "        \"\"\"\n",
    "        row, col = edge_index\n",
    "        batch_size_n_atoms, n_in = x.shape\n",
    "        \n",
    "        # Aggregate neighbors (sum aggregation)\n",
    "        out = torch.zeros_like(x)\n",
    "        if len(row) > 0:\n",
    "            neighbor_features = x[col]\n",
    "            out.index_add_(0, row, neighbor_features)\n",
    "        \n",
    "        # Add self-loops\n",
    "        out = out + x\n",
    "        \n",
    "        # Simple normalization: divide by (degree + 1)\n",
    "        degree = torch.zeros(batch_size_n_atoms, device=x.device)\n",
    "        if len(row) > 0:\n",
    "            degree.index_add_(0, row, torch.ones(len(row), device=x.device))\n",
    "        degree = (degree + 1.0).unsqueeze(-1) + 1e-8\n",
    "        out = out / degree\n",
    "        \n",
    "        # Apply mask\n",
    "        out = out * mask.unsqueeze(-1)\n",
    "        \n",
    "        # Linear transformation\n",
    "        out_flat = out.view(-1, n_in)\n",
    "        out_flat = self.linear(out_flat)\n",
    "        out_flat = F.relu(out_flat)\n",
    "        out = out_flat.view(batch_size_n_atoms, -1)\n",
    "        out = out * mask.unsqueeze(-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_atom_basis=128, n_layers=2, \n",
    "                 n_out=14, max_atoms=23, dropout=0.1):\n",
    "        super(GCN, self).__init__()\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "        self.n_layers = n_layers\n",
    "        self.max_atoms = max_atoms\n",
    "        \n",
    "        # Embedding layer for atomic numbers\n",
    "        self.embedding = nn.Embedding(100, n_atom_basis)\n",
    "        \n",
    "        # GCN layers (simplified - no residual connections)\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            self.gcn_layers.append(GCNConv(n_atom_basis, n_atom_basis))\n",
    "        \n",
    "        # Simplified property prediction head\n",
    "        self.property_head = nn.Sequential(\n",
    "            nn.Linear(n_atom_basis, n_atom_basis // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_atom_basis // 2, n_out)\n",
    "        )\n",
    "        \n",
    "    def build_edge_index(self, positions, mask, cutoff=5.0):\n",
    "        batch_size, n_atoms, _ = positions.shape\n",
    "        device = positions.device\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        pos_i = positions.unsqueeze(2)\n",
    "        pos_j = positions.unsqueeze(1)\n",
    "        diff = pos_i - pos_j\n",
    "        distances = torch.norm(diff, dim=-1)\n",
    "        \n",
    "        mask_i = mask.unsqueeze(2)\n",
    "        mask_j = mask.unsqueeze(1)\n",
    "        neighbor_mask = (mask_i * mask_j).float()\n",
    "        \n",
    "        eye = torch.eye(n_atoms, device=device).unsqueeze(0)\n",
    "        neighbor_mask = neighbor_mask * (1 - eye)\n",
    "        \n",
    "        edge_mask = (distances < cutoff) * neighbor_mask\n",
    "        \n",
    "        # Build edge index for each batch\n",
    "        edge_indices = []\n",
    "        for b in range(batch_size):\n",
    "            edges = torch.nonzero(edge_mask[b], as_tuple=False)\n",
    "            if len(edges) > 0:\n",
    "                edges_offset = edges + b * n_atoms\n",
    "                edge_indices.append(edges_offset.t())\n",
    "            else:\n",
    "                self_loop = torch.arange(n_atoms, device=device) + b * n_atoms\n",
    "                edge_indices.append(torch.stack([self_loop, self_loop]))\n",
    "        \n",
    "        if len(edge_indices) > 0:\n",
    "            edge_index = torch.cat(edge_indices, dim=1)\n",
    "        else:\n",
    "            # Fallback: create self-loops\n",
    "            edge_index = torch.stack([\n",
    "                torch.arange(batch_size * n_atoms, device=device),\n",
    "                torch.arange(batch_size * n_atoms, device=device)\n",
    "            ])\n",
    "        \n",
    "        return edge_index\n",
    "    \n",
    "    def forward(self, atomic_numbers, positions, mask):\n",
    "        batch_size, n_atoms, _ = positions.shape\n",
    "        x = self.embedding(atomic_numbers)\n",
    "        \n",
    "        edge_index = self.build_edge_index(positions, mask)\n",
    "        x_flat = x.view(-1, self.n_atom_basis)\n",
    "        mask_flat = mask.view(-1)\n",
    "        \n",
    "        # Apply GCN layers\n",
    "        for gcn_layer in self.gcn_layers:\n",
    "            x_flat = gcn_layer(x_flat, edge_index, mask_flat)\n",
    "        \n",
    "        # Global pooling: mean over atoms\n",
    "        x = x_flat.view(batch_size, n_atoms, self.n_atom_basis)\n",
    "        mask_expanded = mask.unsqueeze(-1).float()\n",
    "        x_masked = x * mask_expanded\n",
    "        x_sum = x_masked.sum(dim=1)\n",
    "        n_atoms = mask.sum(dim=1, keepdim=True).float()\n",
    "        x_mean = x_sum / (n_atoms + 1e-8)\n",
    "        \n",
    "        # Direct property prediction\n",
    "        properties = self.property_head(x_mean)\n",
    "        \n",
    "        return properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7c707ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM7bDataset(Dataset):\n",
    "    def __init__(self, Z, R, T, max_atoms=23):\n",
    "        self.Z = Z\n",
    "        self.R = R\n",
    "        self.T = T\n",
    "        self.n_molecules = len(Z)\n",
    "        self.max_atoms = max_atoms\n",
    "        self.n_properties = T.shape[1] if T.ndim > 1 else 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_molecules\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        z = torch.from_numpy(self.Z[idx]).long()\n",
    "        r = torch.from_numpy(self.R[idx]).float()\n",
    "        t = torch.from_numpy(self.T[idx]).float() if self.T.ndim > 1 else torch.tensor([self.T[idx]]).float()\n",
    "        \n",
    "        mask = (z > 0).float()\n",
    "        \n",
    "        return z, r, mask, t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a5966",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "Pad/truncate molecules to fixed size (23 atoms max) for batch processing. Handle variable-length molecular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53ef51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_molecular_data(Z, R, max_atoms=23):\n",
    "    n_molecules = len(Z)\n",
    "    \n",
    "    Z_processed = []\n",
    "    R_processed = []\n",
    "    \n",
    "    for i in range(n_molecules):\n",
    "        z_vals = Z[i] if isinstance(Z[i], np.ndarray) else np.array([Z[i]])\n",
    "        z_vals = z_vals.flatten()\n",
    "        \n",
    "        r_vals = R[i] if isinstance(R[i], np.ndarray) else np.zeros((len(z_vals), 3))\n",
    "        if r_vals.ndim == 1:\n",
    "            if len(r_vals) >= len(z_vals) * 3:\n",
    "                r_vals = r_vals[:len(z_vals)*3].reshape(-1, 3)\n",
    "            else:\n",
    "                r_vals = np.zeros((len(z_vals), 3))\n",
    "        elif r_vals.ndim == 2 and r_vals.shape[1] != 3:\n",
    "            r_vals = np.zeros((len(z_vals), 3))\n",
    "        \n",
    "        if r_vals.shape[0] < len(z_vals):\n",
    "            r_padded_temp = np.zeros((len(z_vals), 3))\n",
    "            r_padded_temp[:r_vals.shape[0]] = r_vals\n",
    "            r_vals = r_padded_temp\n",
    "        elif r_vals.shape[0] > len(z_vals):\n",
    "            r_vals = r_vals[:len(z_vals)]\n",
    "        \n",
    "        n_atoms = min(len(z_vals), max_atoms)\n",
    "        z_padded = np.zeros(max_atoms, dtype=np.int64)\n",
    "        r_padded = np.zeros((max_atoms, 3), dtype=np.float32)\n",
    "        \n",
    "        z_padded[:n_atoms] = z_vals[:n_atoms]\n",
    "        r_padded[:n_atoms] = r_vals[:n_atoms]\n",
    "        \n",
    "        Z_processed.append(z_padded)\n",
    "        R_processed.append(r_padded)\n",
    "    \n",
    "    return np.array(Z_processed), np.array(R_processed)\n",
    "\n",
    "Z_processed, R_processed = prepare_molecular_data(Z, R, max_atoms=23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4236b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 5768\n",
      "Validation samples: 721\n",
      "Test samples: 722\n"
     ]
    }
   ],
   "source": [
    "# Split data to 80% train, 10% validation, 10% test\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    np.arange(len(T)), test_size=0.2, random_state=42\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QM7bDataset(\n",
    "    Z_processed[train_idx], \n",
    "    R_processed[train_idx], \n",
    "    T[train_idx],\n",
    "    max_atoms=23\n",
    ")\n",
    "val_dataset = QM7bDataset(\n",
    "    Z_processed[val_idx], \n",
    "    R_processed[val_idx], \n",
    "    T[val_idx],\n",
    "    max_atoms=23\n",
    ")\n",
    "test_dataset = QM7bDataset(\n",
    "    Z_processed[test_idx], \n",
    "    R_processed[test_idx], \n",
    "    T[test_idx],\n",
    "    max_atoms=23\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af1d83c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 17,262\n"
     ]
    }
   ],
   "source": [
    "model = GCN(\n",
    "    n_atom_basis=64,\n",
    "    n_layers=2,\n",
    "    n_out=T.shape[1],\n",
    "    max_atoms=23,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=10\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa5d35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch [1/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  126273.840238  |  Train MAE:  96.974377\n",
      "    Val MSE:    2135.919067  |  Val MAE:    14.405610\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [2/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  3146.978158  |  Train MAE:  16.676259\n",
      "    Val MSE:    1584.598487  |  Val MAE:    7.850763\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [3/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2806.371818  |  Train MAE:  11.877726\n",
      "    Val MSE:    1487.007414  |  Val MAE:    7.852084\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [4/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2817.837142  |  Train MAE:  11.649108\n",
      "    Val MSE:    1718.312025  |  Val MAE:    9.910451\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [5/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2836.415367  |  Train MAE:  11.837128\n",
      "    Val MSE:    1497.901070  |  Val MAE:    8.491252\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [6/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2808.886432  |  Train MAE:  11.905020\n",
      "    Val MSE:    1515.138125  |  Val MAE:    8.308583\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [7/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2712.861282  |  Train MAE:  11.539611\n",
      "    Val MSE:    1497.087567  |  Val MAE:    7.563664\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [8/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2816.961092  |  Train MAE:  11.702125\n",
      "    Val MSE:    1579.940637  |  Val MAE:    8.908022\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [9/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2821.828549  |  Train MAE:  11.712751\n",
      "    Val MSE:    1496.275351  |  Val MAE:    7.566137\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [10/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2866.313021  |  Train MAE:  11.845430\n",
      "    Val MSE:    1589.315629  |  Val MAE:    9.097614\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [11/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2840.456246  |  Train MAE:  11.888259\n",
      "    Val MSE:    1538.173587  |  Val MAE:    8.871812\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [12/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2830.469020  |  Train MAE:  11.848238\n",
      "    Val MSE:    1496.623206  |  Val MAE:    8.149980\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [13/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2810.396183  |  Train MAE:  11.765464\n",
      "    Val MSE:    1497.245230  |  Val MAE:    7.513648\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [14/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2824.503124  |  Train MAE:  11.622433\n",
      "    Val MSE:    1484.638868  |  Val MAE:    7.625772\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [15/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2790.816919  |  Train MAE:  11.609362\n",
      "    Val MSE:    1544.450554  |  Val MAE:    8.582967\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [16/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2900.669603  |  Train MAE:  11.940551\n",
      "    Val MSE:    1569.625478  |  Val MAE:    9.301838\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [17/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2843.554858  |  Train MAE:  11.911383\n",
      "    Val MSE:    1492.074566  |  Val MAE:    8.505946\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [18/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2701.821323  |  Train MAE:  11.654783\n",
      "    Val MSE:    1574.327427  |  Val MAE:    8.894718\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [19/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2790.276821  |  Train MAE:  11.694345\n",
      "    Val MSE:    1477.531542  |  Val MAE:    7.804711\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [20/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2749.642267  |  Train MAE:  11.609366\n",
      "    Val MSE:    1481.238345  |  Val MAE:    8.325337\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [21/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2694.017638  |  Train MAE:  11.483609\n",
      "    Val MSE:    1481.512621  |  Val MAE:    7.718075\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [22/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2901.646470  |  Train MAE:  11.900284\n",
      "    Val MSE:    1488.008540  |  Val MAE:    8.928855\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [23/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2756.707453  |  Train MAE:  11.802544\n",
      "    Val MSE:    1582.799948  |  Val MAE:    8.903656\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [24/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2766.902321  |  Train MAE:  11.927222\n",
      "    Val MSE:    1478.136997  |  Val MAE:    7.909420\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [25/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2832.273219  |  Train MAE:  11.776977\n",
      "    Val MSE:    1527.416033  |  Val MAE:    7.845073\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [26/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2821.771283  |  Train MAE:  11.612127\n",
      "    Val MSE:    1528.014709  |  Val MAE:    8.853907\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [27/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2880.851458  |  Train MAE:  11.828248\n",
      "    Val MSE:    1481.630854  |  Val MAE:    7.991646\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [28/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2780.008486  |  Train MAE:  11.590196\n",
      "    Val MSE:    1630.537109  |  Val MAE:    9.347332\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [29/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2802.935742  |  Train MAE:  11.722532\n",
      "    Val MSE:    1473.396654  |  Val MAE:    7.968839\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [30/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2800.000778  |  Train MAE:  11.642577\n",
      "    Val MSE:    1474.412537  |  Val MAE:    7.764650\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [31/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2758.848349  |  Train MAE:  11.710118\n",
      "    Val MSE:    1505.619613  |  Val MAE:    7.395834\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [32/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2775.965339  |  Train MAE:  11.550625\n",
      "    Val MSE:    1480.898342  |  Val MAE:    8.019242\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [33/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2811.885230  |  Train MAE:  11.903286\n",
      "    Val MSE:    1713.480042  |  Val MAE:    9.696758\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [34/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2784.350682  |  Train MAE:  11.645246\n",
      "    Val MSE:    1560.676654  |  Val MAE:    9.242958\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [35/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2818.795728  |  Train MAE:  11.705939\n",
      "    Val MSE:    1475.228057  |  Val MAE:    7.813671\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [36/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2784.143413  |  Train MAE:  11.822546\n",
      "    Val MSE:    1527.990980  |  Val MAE:    7.564221\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [37/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2663.886916  |  Train MAE:  11.626160\n",
      "    Val MSE:    1468.107117  |  Val MAE:    7.769248\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [38/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2769.927436  |  Train MAE:  11.681301\n",
      "    Val MSE:    1570.670267  |  Val MAE:    8.938856\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [39/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2831.357802  |  Train MAE:  11.782884\n",
      "    Val MSE:    1473.098593  |  Val MAE:    7.890536\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [40/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2760.903869  |  Train MAE:  11.919041\n",
      "    Val MSE:    1468.029090  |  Val MAE:    8.070909\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [41/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2746.103452  |  Train MAE:  11.609591\n",
      "    Val MSE:    1511.784867  |  Val MAE:    8.644594\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [42/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2849.889284  |  Train MAE:  11.790012\n",
      "    Val MSE:    1540.155194  |  Val MAE:    8.725831\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [43/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2917.673616  |  Train MAE:  11.848177\n",
      "    Val MSE:    1471.589034  |  Val MAE:    7.966204\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [44/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2797.318252  |  Train MAE:  11.815945\n",
      "    Val MSE:    1580.478468  |  Val MAE:    9.336181\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [45/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2800.570359  |  Train MAE:  11.764126\n",
      "    Val MSE:    1484.404082  |  Val MAE:    8.503027\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [46/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2721.493093  |  Train MAE:  11.584991\n",
      "    Val MSE:    1471.790477  |  Val MAE:    7.907991\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [47/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2837.755511  |  Train MAE:  11.752757\n",
      "    Val MSE:    1530.987733  |  Val MAE:    7.384605\n",
      "    LR:          0.001000\n",
      "\n",
      "Epoch [48/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2815.020844  |  Train MAE:  11.701476\n",
      "    Val MSE:    1473.919221  |  Val MAE:    8.044679\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [49/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2649.787417  |  Train MAE:  11.202787\n",
      "    Val MSE:    1486.485890  |  Val MAE:    8.102952\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [50/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2678.026198  |  Train MAE:  11.308046\n",
      "    Val MSE:    1526.147153  |  Val MAE:    8.537486\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [51/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2707.323491  |  Train MAE:  11.310074\n",
      "    Val MSE:    1543.893942  |  Val MAE:    8.663857\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [52/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2787.225122  |  Train MAE:  11.551716\n",
      "    Val MSE:    1492.456418  |  Val MAE:    8.210442\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [53/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2687.031433  |  Train MAE:  11.304256\n",
      "    Val MSE:    1460.740261  |  Val MAE:    7.667352\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [54/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2834.360298  |  Train MAE:  11.569110\n",
      "    Val MSE:    1463.318744  |  Val MAE:    7.816446\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [55/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2714.100922  |  Train MAE:  11.394600\n",
      "    Val MSE:    1460.837686  |  Val MAE:    7.617152\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [56/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2749.616276  |  Train MAE:  11.440703\n",
      "    Val MSE:    1487.302960  |  Val MAE:    8.229205\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [57/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2832.636794  |  Train MAE:  11.612743\n",
      "    Val MSE:    1460.554937  |  Val MAE:    7.617753\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [58/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2720.840594  |  Train MAE:  11.461463\n",
      "    Val MSE:    1467.951137  |  Val MAE:    7.486296\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [59/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2696.775563  |  Train MAE:  11.338924\n",
      "    Val MSE:    1575.724530  |  Val MAE:    8.914508\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [60/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2799.735872  |  Train MAE:  11.546307\n",
      "    Val MSE:    1500.632693  |  Val MAE:    8.275786\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [61/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2797.117664  |  Train MAE:  11.616219\n",
      "    Val MSE:    1463.901980  |  Val MAE:    7.816778\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [62/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2752.822309  |  Train MAE:  11.653573\n",
      "    Val MSE:    1463.135267  |  Val MAE:    7.550070\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [63/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2722.082781  |  Train MAE:  11.443082\n",
      "    Val MSE:    1476.680783  |  Val MAE:    8.053490\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [64/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2724.367007  |  Train MAE:  11.361239\n",
      "    Val MSE:    1475.695421  |  Val MAE:    8.161438\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [65/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2779.930804  |  Train MAE:  11.542042\n",
      "    Val MSE:    1558.656797  |  Val MAE:    8.838332\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [66/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2696.736390  |  Train MAE:  11.401411\n",
      "    Val MSE:    1460.566029  |  Val MAE:    7.716179\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [67/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2755.846766  |  Train MAE:  11.523577\n",
      "    Val MSE:    1473.979097  |  Val MAE:    8.007467\n",
      "    LR:          0.000500\n",
      "\n",
      "Epoch [68/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2857.774966  |  Train MAE:  11.670730\n",
      "    Val MSE:    1489.637722  |  Val MAE:    8.362213\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [69/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2792.597364  |  Train MAE:  11.456286\n",
      "    Val MSE:    1520.982470  |  Val MAE:    8.519827\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [70/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2754.815076  |  Train MAE:  11.403096\n",
      "    Val MSE:    1465.535456  |  Val MAE:    7.851959\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [71/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2693.849367  |  Train MAE:  11.373787\n",
      "    Val MSE:    1477.072396  |  Val MAE:    8.077102\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [72/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2697.681641  |  Train MAE:  11.329045\n",
      "    Val MSE:    1462.424895  |  Val MAE:    7.800832\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [73/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2746.111786  |  Train MAE:  11.332290\n",
      "    Val MSE:    1481.644035  |  Val MAE:    8.118286\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [74/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2653.407566  |  Train MAE:  11.205653\n",
      "    Val MSE:    1458.374644  |  Val MAE:    7.644858\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [75/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2787.009219  |  Train MAE:  11.504798\n",
      "    Val MSE:    1473.503755  |  Val MAE:    8.018449\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [76/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2876.230521  |  Train MAE:  11.706017\n",
      "    Val MSE:    1518.065342  |  Val MAE:    8.546480\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [77/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2790.630998  |  Train MAE:  11.530851\n",
      "    Val MSE:    1458.371924  |  Val MAE:    7.644130\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [78/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2692.213423  |  Train MAE:  11.245383\n",
      "    Val MSE:    1466.014627  |  Val MAE:    7.895486\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [79/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2820.332187  |  Train MAE:  11.511811\n",
      "    Val MSE:    1458.019247  |  Val MAE:    7.700712\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [80/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2689.161248  |  Train MAE:  11.224761\n",
      "    Val MSE:    1481.128031  |  Val MAE:    8.116670\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [81/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2749.522362  |  Train MAE:  11.362993\n",
      "    Val MSE:    1490.815170  |  Val MAE:    8.279907\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [82/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2697.870269  |  Train MAE:  11.359748\n",
      "    Val MSE:    1458.147787  |  Val MAE:    7.622807\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [83/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2724.570130  |  Train MAE:  11.362749\n",
      "    Val MSE:    1477.692661  |  Val MAE:    8.057820\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [84/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2690.776355  |  Train MAE:  11.301743\n",
      "    Val MSE:    1490.242471  |  Val MAE:    8.263001\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [85/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2823.223150  |  Train MAE:  11.566189\n",
      "    Val MSE:    1469.834287  |  Val MAE:    7.964499\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [86/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2696.946696  |  Train MAE:  11.296836\n",
      "    Val MSE:    1457.365155  |  Val MAE:    7.649846\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [87/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2768.560258  |  Train MAE:  11.402487\n",
      "    Val MSE:    1492.216701  |  Val MAE:    8.310844\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [88/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2815.506591  |  Train MAE:  11.558404\n",
      "    Val MSE:    1484.535798  |  Val MAE:    8.138778\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [89/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2707.799719  |  Train MAE:  11.406478\n",
      "    Val MSE:    1468.338103  |  Val MAE:    7.934467\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [90/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2788.454417  |  Train MAE:  11.511965\n",
      "    Val MSE:    1459.346372  |  Val MAE:    7.696747\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [91/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2836.099829  |  Train MAE:  11.602562\n",
      "    Val MSE:    1468.204659  |  Val MAE:    7.939395\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [92/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2658.982047  |  Train MAE:  11.280142\n",
      "    Val MSE:    1473.664376  |  Val MAE:    8.004098\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [93/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2723.702049  |  Train MAE:  11.320739\n",
      "    Val MSE:    1501.213801  |  Val MAE:    8.543362\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [94/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2828.976355  |  Train MAE:  11.577916\n",
      "    Val MSE:    1504.188697  |  Val MAE:    8.501453\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [95/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2680.347731  |  Train MAE:  11.342066\n",
      "    Val MSE:    1490.382337  |  Val MAE:    8.233604\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [96/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2802.096486  |  Train MAE:  11.574776\n",
      "    Val MSE:    1482.496423  |  Val MAE:    8.092448\n",
      "    LR:          0.000250\n",
      "\n",
      "Epoch [97/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2734.447043  |  Train MAE:  11.374634\n",
      "    Val MSE:    1458.192529  |  Val MAE:    7.591817\n",
      "    LR:          0.000125\n",
      "\n",
      "Epoch [98/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2777.848958  |  Train MAE:  11.423696\n",
      "    Val MSE:    1465.512894  |  Val MAE:    7.853863\n",
      "    LR:          0.000125\n",
      "\n",
      "Epoch [99/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2766.891487  |  Train MAE:  11.430720\n",
      "    Val MSE:    1458.296580  |  Val MAE:    7.616147\n",
      "    LR:          0.000125\n",
      "\n",
      "Epoch [100/100]\n",
      "  Training... \n",
      "  Validating...   Results:\n",
      "    Train MSE:  2831.757023  |  Train MAE:  11.571225\n",
      "    Val MSE:    1459.256539  |  Val MAE:    7.751345\n",
      "    LR:          0.000125\n",
      "\n",
      "Training completed\n",
      "Total epochs trained: 100\n",
      "Best validation MSE: 1457.365155\n",
      "Best validation MAE: 7.649846\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, epoch=None, total_epochs=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for batch_idx, (z, r, mask, t) in enumerate(loader):\n",
    "        z = z.to(device)\n",
    "        r = r.to(device)\n",
    "        mask = mask.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(z, r, mask)\n",
    "        loss = criterion(predictions, t)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate MAE for this batch\n",
    "        mae = torch.mean(torch.abs(predictions - t)).item()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_mae += mae\n",
    "        n_batches += 1\n",
    "    \n",
    "    if epoch is not None:\n",
    "        print()\n",
    "    \n",
    "    return total_loss / n_batches, total_mae / n_batches\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for z, r, mask, t in loader:\n",
    "            z = z.to(device)\n",
    "            r = r.to(device)\n",
    "            mask = mask.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            predictions = model(z, r, mask)\n",
    "            loss = criterion(predictions, t)\n",
    "            \n",
    "            # Calculate MAE for this batch\n",
    "            mae = torch.mean(torch.abs(predictions - t)).item()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae\n",
    "            n_batches += 1\n",
    "    \n",
    "    return total_loss / n_batches, total_mae / n_batches\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "train_maes = []\n",
    "val_losses = []\n",
    "val_maes = []\n",
    "best_val_loss = float('inf')\n",
    "best_val_mae = float('inf')\n",
    "patience_counter = 0\n",
    "max_patience = 20\n",
    "current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "print(\"Starting Training\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training phase\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}]\")\n",
    "    print(f\"  Training...\", end=' ')\n",
    "    train_loss, train_mae = train_epoch(model, train_loader, criterion, optimizer, device, epoch+1, n_epochs)\n",
    "    train_losses.append(train_loss)\n",
    "    train_maes.append(train_mae)\n",
    "    \n",
    "    # Validation phase\n",
    "    print(f\"  Validating...\", end=' ')\n",
    "    val_loss, val_mae = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_maes.append(val_mae)\n",
    "    \n",
    "    # Update learning rate\n",
    "    old_lr = current_lr\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lr_reduced = old_lr != current_lr\n",
    "    \n",
    "    # Early stopping check (using MSE loss)\n",
    "    improved = val_loss < best_val_loss\n",
    "    if improved:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_mae = val_mae\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), '../best_gcn_model.pth')\n",
    "        save_status = \"Saved\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        save_status = \"\"\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"  Results:\")\n",
    "    print(f\"    Train MSE:  {train_loss:.6f}  |  Train MAE:  {train_mae:.6f}\")\n",
    "    print(f\"    Val MSE:    {val_loss:.6f}  |  Val MAE:    {val_mae:.6f}\")\n",
    "    print(f\"    LR:          {current_lr:.6f}\")\n",
    "    print()\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= max_patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"Training completed\")\n",
    "print(f\"Total epochs trained: {len(train_losses)}\")\n",
    "print(f\"Best validation MSE: {best_val_loss:.6f}\")\n",
    "print(f\"Best validation MAE: {best_val_mae:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fda09cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training curves\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "# MAE curves\n",
    "ax.plot(train_maes, label='Train MAE', linewidth=2)\n",
    "ax.plot(val_maes, label='Validation MAE', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_title('GCN Training Curves - MAE')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16f5848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the test set\n",
      "Test MSE:  1162.958273\n",
      "Test MAE:  7.342368\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model on the test set\")\n",
    "\n",
    "model.load_state_dict(torch.load('../best_gcn_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_mae = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test MSE:  {test_loss:.6f}\")\n",
    "print(f\"Test MAE:  {test_mae:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
